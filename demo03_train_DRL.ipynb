{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from EnvLibs import Environment, RewardKernel, TrafficGenerator\n",
    "from EnvLibs.DRL_EnvSim import DRLResourceSchedulingEnv\n",
    "from EnvLibs.DRL_config import (\n",
    "    get_algorithm_config, \n",
    "    get_environment_config, \n",
    "    get_training_config,\n",
    "    print_algorithm_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCallback(BaseCallback):\n",
    "    \"\"\"Custom callback to track detailed training performance.\"\"\"\n",
    "    \n",
    "    def __init__(self, algorithm_name: str, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.algorithm_name = algorithm_name\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_alphas = []\n",
    "        self.episode_loss_rates = []\n",
    "        self.timesteps = []\n",
    "        self.episodes = 0\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        # Track per-step metrics\n",
    "        if len(self.locals.get('infos', [])) > 0:\n",
    "            info = self.locals['infos'][0]\n",
    "            \n",
    "            # Check if episode ended\n",
    "            if 'episode' in info or self.locals.get('dones', [False])[0]:\n",
    "                self.episodes += 1\n",
    "                \n",
    "                # Log episode metrics\n",
    "                if 'total_packet_loss_rate' in info:\n",
    "                    self.episode_loss_rates.append(info['total_packet_loss_rate'])\n",
    "                    self.timesteps.append(self.num_timesteps)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_environment(action_mode=\"full_action\", use_real_traffic=True, traffic_update_mode=\"sequential\", seed=None):\n",
    "    \"\"\"Create and return the resource scheduling environment.\"\"\"\n",
    "    \n",
    "    env_config = get_environment_config()\n",
    "    \n",
    "\n",
    "    \n",
    "    env = DRLResourceSchedulingEnv(\n",
    "        n_users=env_config[\"n_users\"],\n",
    "        len_window=env_config[\"len_window\"],\n",
    "        r_bar=env_config[\"r_bar\"],\n",
    "        bandwidth=env_config[\"bandwidth\"],\n",
    "        action_mode=action_mode,\n",
    "        observation_mode=\"full\",\n",
    "        max_episode_steps=env_config[\"max_episode_steps\"],\n",
    "        random_seed=seed,\n",
    "        reward_mode=env_config[\"reward_mode\"],\n",
    "        traffic_data_path=\"Results/TrafficData/trafficData.pkl\",  # NEW\n",
    "        use_real_traffic=use_real_traffic,  # NEW\n",
    "        traffic_update_mode=traffic_update_mode  # NEW\n",
    "    )\n",
    "    return Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_drl_agent(algorithm_name: str, env, total_timesteps=None, save_path=None):\n",
    "    \"\"\"Train a DRL agent using the specified algorithm.\"\"\"\n",
    "    \n",
    "    # Get configurations\n",
    "    training_config = get_training_config()\n",
    "    if total_timesteps is None:\n",
    "        total_timesteps = training_config[\"total_timesteps\"]\n",
    "    \n",
    "    if save_path is None:\n",
    "        # Extract environment parameters for the save path\n",
    "        # Access the underlying environment (unwrap Monitor wrapper)\n",
    "        underlying_env = env.unwrapped if hasattr(env, 'unwrapped') else env\n",
    "        n_users = underlying_env.n_users\n",
    "        bandwidth = underlying_env.bandwidth\n",
    "        save_path = f\"{training_config['models_dir']}/{algorithm_name.lower()}_mdp_scheduling_N_u={n_users},B={bandwidth}\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {algorithm_name} Agent\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total timesteps: {total_timesteps}\")\n",
    "    print(f\"Environment: {underlying_env.n_users} users, {underlying_env.bandwidth} bandwidth\")\n",
    "    print(f\"Save path: {save_path}.zip\")\n",
    "\n",
    "    \n",
    "    # Get algorithm configuration\n",
    "    config = get_algorithm_config(algorithm_name, env)\n",
    "    algorithm_class = config[\"class\"]\n",
    "    params = config[\"params\"]\n",
    "\n",
    "    \n",
    "    # Create callback to track performance\n",
    "    callback = TrainingCallback(algorithm_name)\n",
    "    \n",
    "    # Create model\n",
    "    model = algorithm_class(\n",
    "        \"MlpPolicy\", \n",
    "        env, \n",
    "        verbose=1,\n",
    "        device='cpu',\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    print(\"Starting training...\")\n",
    "    model.learn(total_timesteps=total_timesteps, callback=callback)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Save the model\n",
    "    os.makedirs(training_config[\"models_dir\"], exist_ok=True)\n",
    "    model.save(save_path)\n",
    "    \n",
    "    print(f\"{algorithm_name} training completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Model saved to: {save_path}.zip\")\n",
    "    \n",
    "    return model, callback, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env, algorithm_name, num_episodes=10, eval_seed=42):\n",
    "    \"\"\"Evaluate a trained model and return performance metrics.\"\"\"\n",
    "    \n",
    "    episode_rewards = []\n",
    "    episode_loss_rates = []\n",
    "    episode_alphas = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        # Use same seed for fair comparison across algorithms\n",
    "        obs, _ = env.reset(seed=eval_seed + episode)  # ‚Üê FIXED SEED PER EPISODE\n",
    "        episode_reward = 0\n",
    "        episode_alpha_list = []\n",
    "        step_count = 0\n",
    "        \n",
    "        while True:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            episode_alpha_list.append(info['alpha'])\n",
    "            step_count += 1\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                episode_rewards.append(episode_reward)\n",
    "                episode_loss_rates.append(info['total_packet_loss_rate'])\n",
    "                episode_alphas.append(np.mean(episode_alpha_list))\n",
    "                episode_lengths.append(step_count)\n",
    "                break\n",
    "    \n",
    "    return {\n",
    "        'algorithm': algorithm_name,\n",
    "        'avg_reward': np.mean(episode_rewards),\n",
    "        'std_reward': np.std(episode_rewards),\n",
    "        'avg_loss_rate': np.mean(episode_loss_rates),\n",
    "        'std_loss_rate': np.std(episode_loss_rates),\n",
    "        'avg_alpha': np.mean(episode_alphas),\n",
    "        'avg_episode_length': np.mean(episode_lengths),\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_loss_rates': episode_loss_rates,\n",
    "        'episode_alphas': episode_alphas\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_drl_agent(model, env, algorithm_name: str, num_episodes=None, eval_seed=None):\n",
    "    \"\"\"Evaluate a trained DRL agent.\"\"\"\n",
    "    \n",
    "    training_config = get_training_config()\n",
    "    if num_episodes is None:\n",
    "        num_episodes = training_config[\"eval_episodes\"]\n",
    "    if eval_seed is None:\n",
    "        eval_seed = training_config[\"eval_seed\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {algorithm_name} Agent\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    episode_rewards = []\n",
    "    episode_loss_rates = []\n",
    "    episode_alphas = []\n",
    "    episode_lengths = []\n",
    "    episode_actions = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset(seed=eval_seed + episode)\n",
    "        episode_reward = 0\n",
    "        episode_alpha_list = []\n",
    "        episode_action_list = []\n",
    "        step_count = 0\n",
    "        \n",
    "        while True:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            episode_alpha_list.append(info['alpha'])\n",
    "            episode_action_list.append(action.copy() if hasattr(action, 'copy') else action)\n",
    "            step_count += 1\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                episode_rewards.append(episode_reward)\n",
    "                episode_loss_rates.append(info['total_packet_loss_rate'])\n",
    "                episode_alphas.append(np.mean(episode_alpha_list))\n",
    "                episode_lengths.append(step_count)\n",
    "                episode_actions.append(episode_action_list)\n",
    "                break\n",
    "    \n",
    "    # Calculate statistics\n",
    "    results = {\n",
    "        'algorithm': algorithm_name,\n",
    "        'avg_reward': np.mean(episode_rewards),\n",
    "        'std_reward': np.std(episode_rewards),\n",
    "        'avg_loss_rate': np.mean(episode_loss_rates),\n",
    "        'std_loss_rate': np.std(episode_loss_rates),\n",
    "        'avg_alpha': np.mean(episode_alphas),\n",
    "        'avg_episode_length': np.mean(episode_lengths),\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_loss_rates': episode_loss_rates,\n",
    "        'episode_alphas': episode_alphas,\n",
    "        'episode_actions': episode_actions\n",
    "    }\n",
    "    \n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"  Average Reward: {results['avg_reward']:.4f} ¬± {results['std_reward']:.4f}\")\n",
    "    print(f\"  Average Loss Rate: {results['avg_loss_rate']:.4f} ¬± {results['std_loss_rate']:.4f}\")\n",
    "    print(f\"  Average Alpha: {results['avg_alpha']:.4f}\")\n",
    "    print(f\"  Average Episode Length: {results['avg_episode_length']:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_training_results(callback, eval_results, algorithm_name: str, save_plots=True):\n",
    "    \"\"\"Plot training progress and evaluation results.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'{algorithm_name} Agent Training and Evaluation Results', fontsize=16)\n",
    "    \n",
    "    # 1. Training Loss Rates Over Time\n",
    "    if callback.episode_loss_rates and callback.timesteps:\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(callback.timesteps, callback.episode_loss_rates, alpha=0.7, color='blue')\n",
    "        ax1.set_title('Training: Loss Rate Over Time')\n",
    "        ax1.set_xlabel('Training Timesteps')\n",
    "        ax1.set_ylabel('Packet Loss Rate')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'No training data available', \n",
    "                       transform=axes[0, 0].transAxes, ha='center', va='center')\n",
    "        axes[0, 0].set_title('Training: Loss Rate Over Time')\n",
    "    \n",
    "    # 2. Evaluation Reward Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(eval_results['episode_rewards'], bins=15, alpha=0.7, color='orange')\n",
    "    ax2.axvline(eval_results['avg_reward'], color='red', linestyle='--', \n",
    "                label=f'Mean: {eval_results[\"avg_reward\"]:.4f}')\n",
    "    ax2.set_title('Evaluation: Reward Distribution')\n",
    "    ax2.set_xlabel('Episode Reward')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Evaluation Loss Rate Distribution\n",
    "    ax3 = axes[0, 2]\n",
    "    ax3.hist(eval_results['episode_loss_rates'], bins=15, alpha=0.7, color='green')\n",
    "    ax3.axvline(eval_results['avg_loss_rate'], color='red', linestyle='--',\n",
    "                label=f'Mean: {eval_results[\"avg_loss_rate\"]:.4f}')\n",
    "    ax3.set_title('Evaluation: Loss Rate Distribution')\n",
    "    ax3.set_xlabel('Packet Loss Rate')\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Alpha Value Distribution\n",
    "    ax4 = axes[1, 0]\n",
    "    ax4.hist(eval_results['episode_alphas'], bins=15, alpha=0.7, color='purple')\n",
    "    ax4.axvline(eval_results['avg_alpha'], color='red', linestyle='--',\n",
    "                label=f'Mean: {eval_results[\"avg_alpha\"]:.4f}')\n",
    "    ax4.set_title('Evaluation: Alpha Value Distribution')\n",
    "    ax4.set_xlabel('Alpha Value')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Action Space Analysis\n",
    "    ax5 = axes[1, 1]\n",
    "    if eval_results['episode_actions'] and len(eval_results['episode_actions']) > 0:\n",
    "        try:\n",
    "            first_action = eval_results['episode_actions'][0][0]\n",
    "            if hasattr(first_action, '__len__') and len(first_action) > 1:\n",
    "                # Continuous actions\n",
    "                all_actions = []\n",
    "                for ep_actions in eval_results['episode_actions']:\n",
    "                    for action in ep_actions:\n",
    "                        if hasattr(action, '__len__'):\n",
    "                            all_actions.append(action)\n",
    "                \n",
    "                if all_actions:\n",
    "                    all_actions = np.array(all_actions)\n",
    "                    # Plot distribution of first few action dimensions\n",
    "                    colors = ['blue', 'orange', 'green', 'red']\n",
    "                    for i in range(min(4, all_actions.shape[1])):\n",
    "                        ax5.hist(all_actions[:, i], bins=20, alpha=0.5, \n",
    "                                color=colors[i % len(colors)], label=f'Action {i}')\n",
    "                    ax5.set_title('Action Distribution (First 4 Dimensions)')\n",
    "                    ax5.set_xlabel('Action Value')\n",
    "                    ax5.set_ylabel('Frequency')\n",
    "                    ax5.legend()\n",
    "            else:\n",
    "                # Discrete actions\n",
    "                all_actions = []\n",
    "                for ep_actions in eval_results['episode_actions']:\n",
    "                    all_actions.extend(ep_actions)\n",
    "                ax5.hist(all_actions, bins=20, alpha=0.7, color='cyan')\n",
    "                ax5.set_title('Action Distribution (Discrete)')\n",
    "                ax5.set_xlabel('Action Value')\n",
    "                ax5.set_ylabel('Frequency')\n",
    "        except Exception as e:\n",
    "            ax5.text(0.5, 0.5, f'Action analysis failed:\\n{str(e)}', \n",
    "                    transform=ax5.transAxes, ha='center', va='center')\n",
    "            ax5.set_title('Action Analysis (Error)')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No action data available', \n",
    "                transform=ax5.transAxes, ha='center', va='center')\n",
    "        ax5.set_title('Action Distribution')\n",
    "    \n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Performance Summary\n",
    "    ax6 = axes[1, 2]\n",
    "    metrics = ['Avg Reward', 'Avg Loss Rate', 'Avg Alpha']\n",
    "    values = [eval_results['avg_reward'], eval_results['avg_loss_rate'], eval_results['avg_alpha']]\n",
    "    errors = [eval_results['std_reward'], eval_results['std_loss_rate'], 0]\n",
    "    colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "    \n",
    "    bars = ax6.bar(metrics, values, yerr=errors, capsize=5, alpha=0.7, color=colors)\n",
    "    ax6.set_title('Performance Summary')\n",
    "    ax6.set_ylabel('Value')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2, height + (0.01 * height if height > 0 else -0.01 * abs(height)),\n",
    "                f'{value:.4f}', ha='center', va='bottom' if height > 0 else 'top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        training_config = get_training_config()\n",
    "        os.makedirs(training_config[\"plots_dir\"], exist_ok=True)\n",
    "        plot_path = f'{training_config[\"plots_dir\"]}/{algorithm_name.lower()}_results.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to: {plot_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate(algorithm_name: str, model_path: str, action_mode=\"full_action\", num_episodes=None):\n",
    "    \"\"\"Load a trained model and evaluate it.\"\"\"\n",
    "    \n",
    "    print(f\"Loading {algorithm_name} model from {model_path}\")\n",
    "    \n",
    "    # Create environment\n",
    "    env = create_environment(action_mode=action_mode)\n",
    "    \n",
    "    # Get algorithm class\n",
    "    config = get_algorithm_config(algorithm_name, env)\n",
    "    algorithm_class = config[\"class\"]\n",
    "    \n",
    "    # Load model\n",
    "    model = algorithm_class.load(model_path)\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_results = evaluate_drl_agent(model, env, algorithm_name, num_episodes)\n",
    "    \n",
    "    env.close()\n",
    "    return model, eval_results\n",
    "\n",
    "\n",
    "def main(algorithm_name: str = \"SAC\", total_timesteps: int = None, action_mode: str = \"full_action\"):\n",
    "    \"\"\"Main function to train and evaluate a DRL agent.\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"{algorithm_name} Agent Training and Evaluation\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get training configuration\n",
    "    training_config = get_training_config()\n",
    "    if total_timesteps is None:\n",
    "        total_timesteps = training_config[\"total_timesteps\"]\n",
    "    \n",
    "    # Create environment\n",
    "    print(\"Creating environment...\")\n",
    "    env = create_environment(action_mode=action_mode, seed=42)\n",
    "    \n",
    "    # Check environment\n",
    "    print(\"Checking environment...\")\n",
    "    check_env(env.unwrapped)\n",
    "    print(\"Environment check passed!\")\n",
    "    \n",
    "    # Train DRL agent\n",
    "    model, callback, training_time = train_drl_agent(algorithm_name, env, total_timesteps)\n",
    "    \n",
    "    # Evaluate DRL agent\n",
    "    eval_results = evaluate_drl_agent(model, env, algorithm_name)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Algorithm: {algorithm_name}\")\n",
    "    print(f\"Action mode: {action_mode}\")\n",
    "    print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "    print(f\"Total training timesteps: {total_timesteps}\")\n",
    "    print(f\"Average evaluation reward: {eval_results['avg_reward']:.4f} ¬± {eval_results['std_reward']:.4f}\")\n",
    "    print(f\"Average packet loss rate: {eval_results['avg_loss_rate']:.4f} ¬± {eval_results['std_loss_rate']:.4f}\")\n",
    "    print(f\"Average alpha value: {eval_results['avg_alpha']:.4f}\")\n",
    "    print(f\"Model saved as: {training_config['models_dir']}/{algorithm_name.lower()}_mdp_scheduling.zip\")\n",
    "    \n",
    "    env.close()\n",
    "    return model, eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training with SAC...\n",
      "================================================================================\n",
      "SAC Agent Training and Evaluation\n",
      "================================================================================\n",
      "Creating environment...\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      "Checking environment...\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      "Environment check passed!\n",
      "\n",
      "============================================================\n",
      "Training SAC Agent\n",
      "============================================================\n",
      "Total timesteps: 200000\n",
      "Environment: 4 users, 30 bandwidth\n",
      "Save path: models/sac_mdp_scheduling_N_u=4,B=30.zip\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Starting training...\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 161      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.1    |\n",
      "|    critic_loss     | 0.315    |\n",
      "|    ent_coef        | 0.741    |\n",
      "|    ent_coef_loss   | -5.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 999      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 104      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.5    |\n",
      "|    critic_loss     | 0.78     |\n",
      "|    ent_coef        | 0.406    |\n",
      "|    ent_coef_loss   | -15      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2999     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 69       |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60      |\n",
      "|    critic_loss     | 0.966    |\n",
      "|    ent_coef        | 0.224    |\n",
      "|    ent_coef_loss   | -24.4    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4999     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -101     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.5    |\n",
      "|    critic_loss     | 13.3     |\n",
      "|    ent_coef        | 0.125    |\n",
      "|    ent_coef_loss   | -28.2    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6999     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -93.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 189      |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.7    |\n",
      "|    critic_loss     | 1.22     |\n",
      "|    ent_coef        | 0.0821   |\n",
      "|    ent_coef_loss   | -6.5     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8999     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -97.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 241      |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.4    |\n",
      "|    critic_loss     | 0.985    |\n",
      "|    ent_coef        | 0.0625   |\n",
      "|    ent_coef_loss   | -1.18    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -98.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 294      |\n",
      "|    total_timesteps | 14000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.7    |\n",
      "|    critic_loss     | 0.565    |\n",
      "|    ent_coef        | 0.0474   |\n",
      "|    ent_coef_loss   | 1.56     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -94.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 345      |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.7    |\n",
      "|    critic_loss     | 0.661    |\n",
      "|    ent_coef        | 0.0402   |\n",
      "|    ent_coef_loss   | 5.47     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -96      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 398      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -49.4    |\n",
      "|    critic_loss     | 0.584    |\n",
      "|    ent_coef        | 0.0397   |\n",
      "|    ent_coef_loss   | -2.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -94.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -48      |\n",
      "|    critic_loss     | 16.7     |\n",
      "|    ent_coef        | 0.0359   |\n",
      "|    ent_coef_loss   | 16.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -92.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 475      |\n",
      "|    total_timesteps | 22000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.3    |\n",
      "|    critic_loss     | 13.8     |\n",
      "|    ent_coef        | 0.0368   |\n",
      "|    ent_coef_loss   | -1.5     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -91.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 511      |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -41.6    |\n",
      "|    critic_loss     | 0.315    |\n",
      "|    ent_coef        | 0.0298   |\n",
      "|    ent_coef_loss   | 9.61     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -90.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 544      |\n",
      "|    total_timesteps | 26000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -39.9    |\n",
      "|    critic_loss     | 0.304    |\n",
      "|    ent_coef        | 0.0298   |\n",
      "|    ent_coef_loss   | 5.49     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -92.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 581      |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -36.3    |\n",
      "|    critic_loss     | 0.244    |\n",
      "|    ent_coef        | 0.0339   |\n",
      "|    ent_coef_loss   | 2.93     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -89.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 617      |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -33.7    |\n",
      "|    critic_loss     | 3.07     |\n",
      "|    ent_coef        | 0.0277   |\n",
      "|    ent_coef_loss   | -3.27    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 28999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -87.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 653      |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.4    |\n",
      "|    critic_loss     | 0.181    |\n",
      "|    ent_coef        | 0.0196   |\n",
      "|    ent_coef_loss   | -5.21    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -85.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 689      |\n",
      "|    total_timesteps | 34000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.4    |\n",
      "|    critic_loss     | 2.93     |\n",
      "|    ent_coef        | 0.0178   |\n",
      "|    ent_coef_loss   | 7.39     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -85.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 724      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.1    |\n",
      "|    critic_loss     | 0.146    |\n",
      "|    ent_coef        | 0.0183   |\n",
      "|    ent_coef_loss   | -0.689   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -83.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 766      |\n",
      "|    total_timesteps | 38000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.4    |\n",
      "|    critic_loss     | 0.167    |\n",
      "|    ent_coef        | 0.0173   |\n",
      "|    ent_coef_loss   | -3.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -82.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 818      |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.1    |\n",
      "|    critic_loss     | 0.108    |\n",
      "|    ent_coef        | 0.0176   |\n",
      "|    ent_coef_loss   | -13      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -82      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 871      |\n",
      "|    total_timesteps | 42000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 0.117    |\n",
      "|    ent_coef        | 0.0151   |\n",
      "|    ent_coef_loss   | -4.79    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -80.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 925      |\n",
      "|    total_timesteps | 44000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 0.0539   |\n",
      "|    ent_coef        | 0.0115   |\n",
      "|    ent_coef_loss   | -0.613   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 42999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -78.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 979      |\n",
      "|    total_timesteps | 46000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14      |\n",
      "|    critic_loss     | 0.163    |\n",
      "|    ent_coef        | 0.011    |\n",
      "|    ent_coef_loss   | 3.45     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 44999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -76.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 1034     |\n",
      "|    total_timesteps | 48000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.7    |\n",
      "|    critic_loss     | 0.663    |\n",
      "|    ent_coef        | 0.0107   |\n",
      "|    ent_coef_loss   | -3.42    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 46999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -74.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 1086     |\n",
      "|    total_timesteps | 50000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 0.0496   |\n",
      "|    ent_coef        | 0.011    |\n",
      "|    ent_coef_loss   | 4.19     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 48999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -71.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 1139     |\n",
      "|    total_timesteps | 52000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.51    |\n",
      "|    critic_loss     | 0.594    |\n",
      "|    ent_coef        | 0.0104   |\n",
      "|    ent_coef_loss   | -2.11    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 50999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -67.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 1193     |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.05    |\n",
      "|    critic_loss     | 0.0327   |\n",
      "|    ent_coef        | 0.00689  |\n",
      "|    ent_coef_loss   | -4.33    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 52999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -64.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 1246     |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.63    |\n",
      "|    critic_loss     | 0.175    |\n",
      "|    ent_coef        | 0.00506  |\n",
      "|    ent_coef_loss   | 0.152    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 54999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -62.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 1299     |\n",
      "|    total_timesteps | 58000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.54    |\n",
      "|    critic_loss     | 0.152    |\n",
      "|    ent_coef        | 0.00746  |\n",
      "|    ent_coef_loss   | 1.32     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 56999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -60.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 1353     |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.73    |\n",
      "|    critic_loss     | 0.111    |\n",
      "|    ent_coef        | 0.00598  |\n",
      "|    ent_coef_loss   | 16.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 58999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -56.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 1406     |\n",
      "|    total_timesteps | 62000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.84    |\n",
      "|    critic_loss     | 0.0197   |\n",
      "|    ent_coef        | 0.00452  |\n",
      "|    ent_coef_loss   | -4.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 60999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -53.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 1461     |\n",
      "|    total_timesteps | 64000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.05    |\n",
      "|    critic_loss     | 0.0544   |\n",
      "|    ent_coef        | 0.00378  |\n",
      "|    ent_coef_loss   | -5.52    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 62999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -51.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 1517     |\n",
      "|    total_timesteps | 66000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.36    |\n",
      "|    critic_loss     | 0.0218   |\n",
      "|    ent_coef        | 0.00341  |\n",
      "|    ent_coef_loss   | -4.79    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 64999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -47.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 1572     |\n",
      "|    total_timesteps | 68000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.77    |\n",
      "|    critic_loss     | 0.032    |\n",
      "|    ent_coef        | 0.00241  |\n",
      "|    ent_coef_loss   | 13.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 66999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -45      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 1628     |\n",
      "|    total_timesteps | 70000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.13    |\n",
      "|    critic_loss     | 0.0227   |\n",
      "|    ent_coef        | 0.00277  |\n",
      "|    ent_coef_loss   | 2.46     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 68999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -42.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 1684     |\n",
      "|    total_timesteps | 72000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.686   |\n",
      "|    critic_loss     | 0.0163   |\n",
      "|    ent_coef        | 0.00236  |\n",
      "|    ent_coef_loss   | -2.65    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 70999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -39.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 1741     |\n",
      "|    total_timesteps | 74000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.297   |\n",
      "|    critic_loss     | 0.0183   |\n",
      "|    ent_coef        | 0.00202  |\n",
      "|    ent_coef_loss   | 2.44     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 72999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -37.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 1778     |\n",
      "|    total_timesteps | 76000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0728   |\n",
      "|    critic_loss     | 0.0172   |\n",
      "|    ent_coef        | 0.00186  |\n",
      "|    ent_coef_loss   | -0.0668  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 74999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -33      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 1808     |\n",
      "|    total_timesteps | 78000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.417    |\n",
      "|    critic_loss     | 0.014    |\n",
      "|    ent_coef        | 0.00164  |\n",
      "|    ent_coef_loss   | -4.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 76999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -31.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 1838     |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.683    |\n",
      "|    critic_loss     | 0.017    |\n",
      "|    ent_coef        | 0.00159  |\n",
      "|    ent_coef_loss   | 1.57     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 78999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -29.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 1866     |\n",
      "|    total_timesteps | 82000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.825    |\n",
      "|    critic_loss     | 0.014    |\n",
      "|    ent_coef        | 0.00144  |\n",
      "|    ent_coef_loss   | 2.83     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 80999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -27.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 1895     |\n",
      "|    total_timesteps | 84000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.987    |\n",
      "|    critic_loss     | 0.0207   |\n",
      "|    ent_coef        | 0.00223  |\n",
      "|    ent_coef_loss   | 8.7      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 82999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -24.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 1924     |\n",
      "|    total_timesteps | 86000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.08     |\n",
      "|    critic_loss     | 0.0129   |\n",
      "|    ent_coef        | 0.00219  |\n",
      "|    ent_coef_loss   | -9.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 84999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -23.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 1954     |\n",
      "|    total_timesteps | 88000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.18     |\n",
      "|    critic_loss     | 0.0241   |\n",
      "|    ent_coef        | 0.00181  |\n",
      "|    ent_coef_loss   | -2.61    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 86999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -21.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 1982     |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.24     |\n",
      "|    critic_loss     | 0.0162   |\n",
      "|    ent_coef        | 0.00172  |\n",
      "|    ent_coef_loss   | -0.246   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 88999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -19      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 2011     |\n",
      "|    total_timesteps | 92000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.37     |\n",
      "|    critic_loss     | 0.0111   |\n",
      "|    ent_coef        | 0.00146  |\n",
      "|    ent_coef_loss   | -1.75    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 90999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -17.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 2045     |\n",
      "|    total_timesteps | 94000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.42     |\n",
      "|    critic_loss     | 0.0137   |\n",
      "|    ent_coef        | 0.00141  |\n",
      "|    ent_coef_loss   | 6.5      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 92999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -16.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 2073     |\n",
      "|    total_timesteps | 96000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.48     |\n",
      "|    critic_loss     | 0.0177   |\n",
      "|    ent_coef        | 0.00139  |\n",
      "|    ent_coef_loss   | -1.72    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -15.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 2102     |\n",
      "|    total_timesteps | 98000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.6      |\n",
      "|    critic_loss     | 0.02     |\n",
      "|    ent_coef        | 0.00151  |\n",
      "|    ent_coef_loss   | -3.59    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 96999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -14.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 2130     |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.66     |\n",
      "|    critic_loss     | 0.0088   |\n",
      "|    ent_coef        | 0.00148  |\n",
      "|    ent_coef_loss   | 0.82     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 98999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -14.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 2158     |\n",
      "|    total_timesteps | 102000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.69     |\n",
      "|    critic_loss     | 0.0206   |\n",
      "|    ent_coef        | 0.00135  |\n",
      "|    ent_coef_loss   | 6.08     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 100999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -14      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 2187     |\n",
      "|    total_timesteps | 104000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.83     |\n",
      "|    critic_loss     | 0.00911  |\n",
      "|    ent_coef        | 0.00169  |\n",
      "|    ent_coef_loss   | -3.41    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 102999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -13.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 2218     |\n",
      "|    total_timesteps | 106000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.89     |\n",
      "|    critic_loss     | 0.011    |\n",
      "|    ent_coef        | 0.00187  |\n",
      "|    ent_coef_loss   | 0.622    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 104999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -13      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 2255     |\n",
      "|    total_timesteps | 108000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.91     |\n",
      "|    critic_loss     | 0.0199   |\n",
      "|    ent_coef        | 0.00124  |\n",
      "|    ent_coef_loss   | 4.85     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 106999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -12.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2288     |\n",
      "|    total_timesteps | 110000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.88     |\n",
      "|    critic_loss     | 0.0115   |\n",
      "|    ent_coef        | 0.00143  |\n",
      "|    ent_coef_loss   | -11.3    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 108999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -12.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2317     |\n",
      "|    total_timesteps | 112000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.87     |\n",
      "|    critic_loss     | 0.0217   |\n",
      "|    ent_coef        | 0.00157  |\n",
      "|    ent_coef_loss   | 3.7      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 110999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -12      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2346     |\n",
      "|    total_timesteps | 114000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.93     |\n",
      "|    critic_loss     | 0.0205   |\n",
      "|    ent_coef        | 0.00213  |\n",
      "|    ent_coef_loss   | 6.71     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 112999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -11.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2375     |\n",
      "|    total_timesteps | 116000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.93     |\n",
      "|    critic_loss     | 0.0233   |\n",
      "|    ent_coef        | 0.00212  |\n",
      "|    ent_coef_loss   | -4.83    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 114999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -11.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2405     |\n",
      "|    total_timesteps | 118000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.97     |\n",
      "|    critic_loss     | 0.0216   |\n",
      "|    ent_coef        | 0.00158  |\n",
      "|    ent_coef_loss   | 1.37     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 116999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -11.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2434     |\n",
      "|    total_timesteps | 120000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.96     |\n",
      "|    critic_loss     | 0.0206   |\n",
      "|    ent_coef        | 0.00175  |\n",
      "|    ent_coef_loss   | -0.312   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 118999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -11.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2463     |\n",
      "|    total_timesteps | 122000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2        |\n",
      "|    critic_loss     | 0.0213   |\n",
      "|    ent_coef        | 0.00156  |\n",
      "|    ent_coef_loss   | 3.1      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 120999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -11.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2493     |\n",
      "|    total_timesteps | 124000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.0214   |\n",
      "|    ent_coef        | 0.00137  |\n",
      "|    ent_coef_loss   | -1.84    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 122999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2527     |\n",
      "|    total_timesteps | 126000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.03     |\n",
      "|    critic_loss     | 0.00689  |\n",
      "|    ent_coef        | 0.00147  |\n",
      "|    ent_coef_loss   | 2.05     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 124999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2566     |\n",
      "|    total_timesteps | 128000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.02     |\n",
      "|    critic_loss     | 0.00477  |\n",
      "|    ent_coef        | 0.00138  |\n",
      "|    ent_coef_loss   | 4.41     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 126999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 2597     |\n",
      "|    total_timesteps | 130000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.02     |\n",
      "|    critic_loss     | 0.0358   |\n",
      "|    ent_coef        | 0.00135  |\n",
      "|    ent_coef_loss   | 1.23     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 128999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 2634     |\n",
      "|    total_timesteps | 132000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.00638  |\n",
      "|    ent_coef        | 0.00169  |\n",
      "|    ent_coef_loss   | -3.69    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 130999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2685     |\n",
      "|    total_timesteps | 134000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.05     |\n",
      "|    critic_loss     | 0.0324   |\n",
      "|    ent_coef        | 0.00142  |\n",
      "|    ent_coef_loss   | 2.21     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 132999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2744     |\n",
      "|    total_timesteps | 136000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.0345   |\n",
      "|    ent_coef        | 0.00156  |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 134999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 2804     |\n",
      "|    total_timesteps | 138000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.07     |\n",
      "|    critic_loss     | 0.00454  |\n",
      "|    ent_coef        | 0.00169  |\n",
      "|    ent_coef_loss   | 10.5     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 136999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2864     |\n",
      "|    total_timesteps | 140000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.08     |\n",
      "|    critic_loss     | 0.0223   |\n",
      "|    ent_coef        | 0.00172  |\n",
      "|    ent_coef_loss   | -4.59    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 138999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2924     |\n",
      "|    total_timesteps | 142000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.1      |\n",
      "|    critic_loss     | 0.00421  |\n",
      "|    ent_coef        | 0.00154  |\n",
      "|    ent_coef_loss   | 2.76     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 140999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 2984     |\n",
      "|    total_timesteps | 144000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.0221   |\n",
      "|    ent_coef        | 0.00154  |\n",
      "|    ent_coef_loss   | -2.57    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 142999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.86    |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 3043     |\n",
      "|    total_timesteps | 146000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06     |\n",
      "|    critic_loss     | 0.00276  |\n",
      "|    ent_coef        | 0.00138  |\n",
      "|    ent_coef_loss   | 0.0416   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 144999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.86    |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 3102     |\n",
      "|    total_timesteps | 148000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.0031   |\n",
      "|    ent_coef        | 0.00177  |\n",
      "|    ent_coef_loss   | -8.53    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 146999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.71    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 3161     |\n",
      "|    total_timesteps | 150000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.02     |\n",
      "|    critic_loss     | 0.0028   |\n",
      "|    ent_coef        | 0.00167  |\n",
      "|    ent_coef_loss   | 1.24     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 148999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.55    |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 3219     |\n",
      "|    total_timesteps | 152000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.01     |\n",
      "|    critic_loss     | 0.00335  |\n",
      "|    ent_coef        | 0.0017   |\n",
      "|    ent_coef_loss   | -3.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 150999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.46    |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 3277     |\n",
      "|    total_timesteps | 154000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.01     |\n",
      "|    critic_loss     | 0.00299  |\n",
      "|    ent_coef        | 0.00179  |\n",
      "|    ent_coef_loss   | 0.139    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 152999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.26    |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 3337     |\n",
      "|    total_timesteps | 156000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2        |\n",
      "|    critic_loss     | 0.00385  |\n",
      "|    ent_coef        | 0.00175  |\n",
      "|    ent_coef_loss   | -2.64    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 154999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.03    |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 3398     |\n",
      "|    total_timesteps | 158000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.02     |\n",
      "|    critic_loss     | 0.0179   |\n",
      "|    ent_coef        | 0.00156  |\n",
      "|    ent_coef_loss   | 2.21     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 156999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.54    |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 3458     |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.05     |\n",
      "|    critic_loss     | 0.0182   |\n",
      "|    ent_coef        | 0.0018   |\n",
      "|    ent_coef_loss   | -2.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 158999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.37    |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 3517     |\n",
      "|    total_timesteps | 162000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.00303  |\n",
      "|    ent_coef        | 0.00159  |\n",
      "|    ent_coef_loss   | 7.59     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 160999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 3576     |\n",
      "|    total_timesteps | 164000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.0023   |\n",
      "|    ent_coef        | 0.00153  |\n",
      "|    ent_coef_loss   | 6.95     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 162999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.26    |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 3636     |\n",
      "|    total_timesteps | 166000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.032    |\n",
      "|    ent_coef        | 0.00156  |\n",
      "|    ent_coef_loss   | -0.771   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 164999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.26    |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 3697     |\n",
      "|    total_timesteps | 168000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06     |\n",
      "|    critic_loss     | 0.0184   |\n",
      "|    ent_coef        | 0.00144  |\n",
      "|    ent_coef_loss   | -0.269   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 166999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 3757     |\n",
      "|    total_timesteps | 170000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06     |\n",
      "|    critic_loss     | 0.002    |\n",
      "|    ent_coef        | 0.00158  |\n",
      "|    ent_coef_loss   | -5.42    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 168999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.42    |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 3818     |\n",
      "|    total_timesteps | 172000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06     |\n",
      "|    critic_loss     | 0.00228  |\n",
      "|    ent_coef        | 0.00174  |\n",
      "|    ent_coef_loss   | 3.79     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 170999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.39    |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 3880     |\n",
      "|    total_timesteps | 174000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06     |\n",
      "|    critic_loss     | 0.0344   |\n",
      "|    ent_coef        | 0.00153  |\n",
      "|    ent_coef_loss   | 1.41     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 172999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 3941     |\n",
      "|    total_timesteps | 176000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06     |\n",
      "|    critic_loss     | 0.016    |\n",
      "|    ent_coef        | 0.00142  |\n",
      "|    ent_coef_loss   | 4.49     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 174999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -8.44    |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 4002     |\n",
      "|    total_timesteps | 178000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.05     |\n",
      "|    critic_loss     | 0.00204  |\n",
      "|    ent_coef        | 0.0014   |\n",
      "|    ent_coef_loss   | -3.46    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 176999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.03    |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 4063     |\n",
      "|    total_timesteps | 180000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.95     |\n",
      "|    critic_loss     | 0.00366  |\n",
      "|    ent_coef        | 0.00238  |\n",
      "|    ent_coef_loss   | -27.3    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 178999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -9.79    |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 4123     |\n",
      "|    total_timesteps | 182000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.14     |\n",
      "|    critic_loss     | 0.0549   |\n",
      "|    ent_coef        | 0.00192  |\n",
      "|    ent_coef_loss   | 25.7     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 180999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4183     |\n",
      "|    total_timesteps | 184000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.27     |\n",
      "|    critic_loss     | 0.0032   |\n",
      "|    ent_coef        | 0.0017   |\n",
      "|    ent_coef_loss   | -5.66    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 182999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4242     |\n",
      "|    total_timesteps | 186000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.39     |\n",
      "|    critic_loss     | 0.0147   |\n",
      "|    ent_coef        | 0.00142  |\n",
      "|    ent_coef_loss   | -1.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 184999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4302     |\n",
      "|    total_timesteps | 188000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.43     |\n",
      "|    critic_loss     | 0.0188   |\n",
      "|    ent_coef        | 0.0014   |\n",
      "|    ent_coef_loss   | -9.74    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 186999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4363     |\n",
      "|    total_timesteps | 190000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.51     |\n",
      "|    critic_loss     | 0.0106   |\n",
      "|    ent_coef        | 0.00125  |\n",
      "|    ent_coef_loss   | 8.56     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 188999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4423     |\n",
      "|    total_timesteps | 192000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.54     |\n",
      "|    critic_loss     | 0.0118   |\n",
      "|    ent_coef        | 0.00123  |\n",
      "|    ent_coef_loss   | 7.77     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 190999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4483     |\n",
      "|    total_timesteps | 194000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.59     |\n",
      "|    critic_loss     | 0.00184  |\n",
      "|    ent_coef        | 0.0011   |\n",
      "|    ent_coef_loss   | -1.62    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 192999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4543     |\n",
      "|    total_timesteps | 196000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.62     |\n",
      "|    critic_loss     | 0.00226  |\n",
      "|    ent_coef        | 0.00119  |\n",
      "|    ent_coef_loss   | -2.65    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 194999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 4602     |\n",
      "|    total_timesteps | 198000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.65     |\n",
      "|    critic_loss     | 0.0189   |\n",
      "|    ent_coef        | 0.00132  |\n",
      "|    ent_coef_loss   | -1.83    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 196999   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | -10.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 4662     |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.72     |\n",
      "|    critic_loss     | 0.00302  |\n",
      "|    ent_coef        | 0.0014   |\n",
      "|    ent_coef_loss   | 1.52     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 198999   |\n",
      "---------------------------------\n",
      "SAC training completed in 4662.85 seconds\n",
      "Model saved to: models/sac_mdp_scheduling_N_u=4,B=30.zip\n",
      "\n",
      "============================================================\n",
      "Evaluating SAC Agent\n",
      "============================================================\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      " Loaded real traffic data from: Results/TrafficData/trafficData.pkl\n",
      "   Traffic data shape: (104066,)\n",
      "Evaluation Results:\n",
      "  Average Reward: -6.4993 ¬± 0.6440\n",
      "  Average Loss Rate: 0.0139 ¬± 0.0015\n",
      "  Average Alpha: 0.7039\n",
      "  Average Episode Length: 500.00\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "Algorithm: SAC\n",
      "Action mode: full_action\n",
      "Training completed in: 4662.85 seconds\n",
      "Total training timesteps: 200000\n",
      "Average evaluation reward: -6.4993 ¬± 0.6440\n",
      "Average packet loss rate: 0.0139 ¬± 0.0015\n",
      "Average alpha value: 0.7039\n",
      "Model saved as: models/sac_mdp_scheduling.zip\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configuration - change these parameters as needed\n",
    "    ALGORITHM = \"SAC\"           # Options: \"SAC\", \"PPO\", \"A2C\", \"TD3\", \"DQN\"\n",
    "    TIMESTEPS = 200000         # Training timesteps\n",
    "    ACTION_MODE = \"full_action\" # Options: \"full_action\", \"alpha_only\", \"discrete_alpha\"\n",
    "    \n",
    "    \n",
    "    # Run training and evaluation\n",
    "    print(f\"\\nStarting training with {ALGORITHM}...\")\n",
    "    model, results = main(\n",
    "        algorithm_name=ALGORITHM, \n",
    "        total_timesteps=TIMESTEPS, \n",
    "        action_mode=ACTION_MODE\n",
    "    )\n",
    "    \n",
    "    # Example of loading and evaluating a saved model:\n",
    "    # print(\"\\nExample: Loading and evaluating saved model...\")\n",
    "    # model, results = load_and_evaluate(\"SAC\", \"models/sac_mdp_scheduling.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
